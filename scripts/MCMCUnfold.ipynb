{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25a59b3-650c-4f34-b664-0ca0ad1b852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2393283-75e3-472c-b539-21be002ec16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams[\"axes.formatter.use_mathtext\"] = True\n",
    "leg_size = 14\n",
    "\n",
    "def SetGrid(ratio=True):\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    if ratio:\n",
    "        gs = gridspec.GridSpec(2, 1, height_ratios=[3,1]) \n",
    "        gs.update(wspace=0.025, hspace=0.1)\n",
    "    else:\n",
    "        gs = gridspec.GridSpec(1, 1)\n",
    "    return fig,gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc749fb-2efc-4260-bd60-82d79b6b2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['mass','mult','width','sdms','tau2s','zgs']\n",
    "labels = [\"Jet Mass $m$ [GeV]\", \"Jet Constituent Multiplicity $M$\", \"Jet Width $\\omega$\",\n",
    "          r\"Soft Drop Jet Mass $\\rho$\", r\"N-subjetiness Ratio $\\tau_{21}^{\\beta=1}$\", \"Groomed Jet Momentum Fraction $z_g$\"]\n",
    "R_BinVals, resp = {}, {}\n",
    "T_sim_obs, R_sim_obs, T_data_obs, R_data_obs  = {},{},{},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812a4c2b-f29b-48e9-b98e-f864b81bc7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_truth(n_samples: int) -> np.ndarray:\n",
    "    return np.random.normal(size=n_samples)\n",
    "\n",
    "def confound(\n",
    "    samples: np.ndarray,\n",
    "    resolution: float,\n",
    ") -> np.ndarray:\n",
    "    noise = np.random.normal(loc=0., scale=resolution, size=samples.shape)\n",
    "    return samples + noise\n",
    "\n",
    "def generate_response(\n",
    "    n_samples: int, \n",
    "    bins: list[float],\n",
    "    resolution: float,\n",
    ") -> np.ndarray:\n",
    "    truth_data = np.random.normal(size=n_samples)\n",
    "    truth_hist, _ = np.histogram(truth_data, bins=bins)\n",
    "    observed_data = confound(truth_data, resolution=resolution)\n",
    "    observed_hist, _ = np.histogram(observed_data, bins=bins)\n",
    "    migrations, _, _ = np.histogram2d(observed_data, truth_data, bins=bins)\n",
    "    response = migrations / truth_hist\n",
    "    np.testing.assert_almost_equal(np.dot(response, truth_hist), observed_hist)\n",
    "    return truth_hist, response\n",
    "\n",
    "def generate_pseudoexperiment(\n",
    "    n_samples: int,\n",
    "    bins: list[float],\n",
    "    resolution: float,\n",
    ") -> dict[str, np.ndarray]:\n",
    "    truth_data = generate_truth(n_samples)\n",
    "    truth_hist, _ = np.histogram(truth_data, bins=bins)\n",
    "    observed_data = confound(truth_data, resolution=resolution)\n",
    "    observed_hist, _ = np.histogram(observed_data, bins=bins)\n",
    "    return {\"truth\": truth_hist, \"observed\": observed_hist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b3cd56f-b2fd-4ad5-8fee-25fc0bb77a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior(\n",
    "    observed_hist: np.ndarray,\n",
    "    response: np.ndarray,\n",
    "    lower: np.ndarray,\n",
    "    upper: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    model = pm.Model()\n",
    "\n",
    "    with model:\n",
    "        params = pm.DiscreteUniform(\n",
    "            \"params\", \n",
    "            lower=lower, \n",
    "            upper=upper,\n",
    "        )\n",
    "        likelihood = pm.Poisson(\n",
    "            \"likelihood\", mu=pm.math.dot(response, params),\n",
    "            observed=observed_hist,\n",
    "        )\n",
    "        trace = pm.sample(draws=50000, tune=10000)\n",
    "    return trace.posterior.params[0].to_numpy()\n",
    "\n",
    "def plot_posterior(\n",
    "    posterior: np.ndarray,\n",
    "    truth_hist: np.ndarray,\n",
    "    positions:list[float] = [-4.25, -2.75, -1.5, -0.75, -0.25, 0.25, 0.75, 1.5, 2.75, 4.25],\n",
    "    xerr: list[float] = [1, 0.75, 0.5, 0.25, 0.25, 0.25, 0.25, 0.5, 0.75, 1],\n",
    "):\n",
    "    vp = plt.violinplot(\n",
    "        posterior,\n",
    "        positions=positions,\n",
    "        showextrema=False,\n",
    "    )\n",
    "    eb = plt.errorbar(\n",
    "        x=positions,\n",
    "        y=truth_hist,\n",
    "        xerr=xerr,\n",
    "        fmt=\".\",\n",
    "    )\n",
    "    plt.legend([vp[\"bodies\"][0], eb.lines], [\"Posterior\", \"Truth\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab64d9ff-32fb-433f-b415-55095d1dfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    zjets = np.load(\"zjets_{}.npz\".format(key))\n",
    "    R_BinVals[key] = zjets[\"bins\"]\n",
    "    T_sim_obs[key], _ = np.histogram(zjets[\"t_sim\"], bins=R_BinVals[key])\n",
    "    R_sim_obs[key], _ = np.histogram(zjets[\"r_sim\"], bins=R_BinVals[key])\n",
    "    T_data_obs[key], _ = np.histogram(zjets[\"t_data\"], bins=R_BinVals[key])\n",
    "    R_data_obs[key], _ = np.histogram(zjets[\"r_data\"], bins=R_BinVals[key])\n",
    "    migrations, _, _  = np.histogram2d(zjets[\"r_sim\"], zjets[\"t_sim\"], bins=R_BinVals[key])\n",
    "    resp[key] = migrations / T_sim_obs[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8dbe807-5468-483d-8d0d-bd370dc54b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (pytensor.graph.rewriting.basic): Rewrite failure due to: constant_folding\n",
      "ERROR (pytensor.graph.rewriting.basic): node: Floor([563001.19 ... .81963404])\n",
      "ERROR (pytensor.graph.rewriting.basic): TRACEBACK:\n",
      "ERROR (pytensor.graph.rewriting.basic): Traceback (most recent call last):\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/graph/rewriting/basic.py\", line 1922, in process_node\n",
      "    replacements = node_rewriter.transform(fgraph, node)\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/graph/rewriting/basic.py\", line 1081, in transform\n",
      "    return self.fn(fgraph, node)\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/tensor/rewriting/basic.py\", line 1110, in constant_folding\n",
      "    thunk = node.op.make_thunk(node, storage_map, compute_map, no_recycling=[])\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/link/c/op.py\", line 119, in make_thunk\n",
      "    return self.make_c_thunk(node, storage_map, compute_map, no_recycling)\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/link/c/op.py\", line 84, in make_c_thunk\n",
      "    outputs = cl.make_thunk(\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/link/c/basic.py\", line 1189, in make_thunk\n",
      "    cthunk, module, in_storage, out_storage, error_storage = self.__compile__(\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/link/c/basic.py\", line 1109, in __compile__\n",
      "    thunk, module = self.cthunk_factory(\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/link/c/basic.py\", line 1630, in cthunk_factory\n",
      "    cache = get_module_cache()\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/link/c/basic.py\", line 55, in get_module_cache\n",
      "    return _get_module_cache(config.compiledir, init_args=init_args)\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/link/c/cmodule.py\", line 1636, in get_module_cache\n",
      "    _module_cache = ModuleCache(dirname, **init_args)\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/link/c/cmodule.py\", line 721, in __init__\n",
      "    self.refresh()\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/link/c/cmodule.py\", line 804, in refresh\n",
      "    with lock_ctx():\n",
      "  File \"/global/common/software/nersc9/tensorflow/2.9.0/lib/python3.9/contextlib.py\", line 119, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/global/homes/j/jing/.local/perlmutter/tensorflow2.9.0/lib/python3.9/site-packages/pytensor/compile/compilelock.py\", line 76, in lock_ctx\n",
      "    fl.acquire(timeout=timeout)\n",
      "  File \"/global/common/software/nersc9/tensorflow/2.9.0/lib/python3.9/site-packages/filelock/_api.py\", line 304, in acquire\n",
      "    raise Timeout(lock_filename)  # noqa: TRY301\n",
      "filelock._error.Timeout: The file lock '/global/u1/j/jing/.pytensor/compiledir_Linux-5.14-65_13.0.73-cray_shasta_c-x86_64-with-glibc2.31-x86_64-3.9.19-64/.lock' could not be acquired.\n",
      "\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "Metropolis: [params]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='240000' class='' max='240000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [240000/240000 00:20&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 10_000 tune and 50_000 draw iterations (40_000 + 200_000 draws total) took 21 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, binvals, label in zip(T_sim_obs.keys(), R_BinVals, labels):\n",
    "    if key != 'width': continue\n",
    "    t = T_data_obs[key]\n",
    "    bins = np.array(R_BinVals[key])\n",
    "    bincents = 0.5*(bins[1:]+bins[:-1])\n",
    "    posterior = compute_posterior(\n",
    "        observed_hist = R_data_obs[key],\n",
    "        response = resp[key],\n",
    "        lower=t - 5*t**0.5,\n",
    "        upper=t + 5*t**0.5,\n",
    "    )\n",
    "    np.savez_compressed(\"fpu_data_{}\".format(key)+\".npz\", **{\"bins\": bincents, \"m\": R_data_obs[key], \"t\": t, \"fbu\": posterior, \"R\": resp[key]})\n",
    "\n",
    "    plt.errorbar(x=bincents, y=T_data_obs[key], yerr = np.sqrt(t), ls=\":\")\n",
    "    plt.errorbar(x=bincents, y=np.mean(posterior,axis=0), yerr=np.std(posterior,axis=0))\n",
    "    plt.savefig('fbu_sim_{}.png'.format(key),bbox_inches='tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeee46c3-0453-4ef7-a8ff-998a59b8dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce2579cf-7ef3-44ad-8161-0995cb9ebfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.0\n",
      "1.26.3\n"
     ]
    }
   ],
   "source": [
    "print(tfp.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dee7dcc7-f014-4399-b37f-e41d9c2e7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IBU(data, init, r, det_binwidth=1, mc_binwidth=1, it=10):\n",
    "    \n",
    "    # initialize the truth distribution to the prior\n",
    "    phis = [init]\n",
    "    \n",
    "    # iterate the procedure\n",
    "    for i in range(it):\n",
    "        \n",
    "        # update the estimate for the matrix m\n",
    "        m = r * phis[-1]\n",
    "        m /= (m.sum(axis=1)[:,np.newaxis] + 10**-50)\n",
    "\n",
    "        # update the estimate for the truth distribution\n",
    "        # the factors of binwidth show up here to change probabilities into probability densities\n",
    "        phis.append(np.dot(m.T, data)*det_binwidth/mc_binwidth)\n",
    "        \n",
    "    return phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9990f806-779f-42c2-9d43-66abc2f3c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLE(model,ymes,ndim):\n",
    "    x = tf.Variable(ndim*[1.0/ndim])\n",
    "    loss = lambda: -model.log_prob(x, bijector_kwargs={'conditional_input': ymes})\n",
    "    losses = tfp.math.minimize(loss,\n",
    "                               num_steps=10000,\n",
    "                               #convergence_criterion=(\n",
    "                               #     tfp.optimizers.convergence_criteria.LossNotDecreasing(atol=0.001)),\n",
    "                               trainable_variables=[x],\n",
    "                               optimizer=tf.optimizers.Adam(learning_rate=0.001))\n",
    "    return x\n",
    "\n",
    "def MADE(data_shape, cond_shape):\n",
    "    # Density estimation with MADE.\n",
    "    made = tfb.AutoregressiveNetwork(params=2,\n",
    "                                     hidden_units=[100,100,100], #To be changed when using bigger histograms\n",
    "                                     event_shape=data_shape,\n",
    "                                     activation='swish',\n",
    "                                     conditional=True,\n",
    "                                     conditional_event_shape=cond_shape,\n",
    "                                    )\n",
    "    distribution = tfd.TransformedDistribution(\n",
    "        distribution=tfd.Sample(tfd.Normal(loc=0., scale=1.), sample_shape=[data_shape]),\n",
    "        bijector=tfb.MaskedAutoregressiveFlow(made))\n",
    "\n",
    "    # Construct and fit model.\n",
    "    x_ = tfkl.Input(shape=(data_shape,), dtype=tf.float32)\n",
    "    c_ = tfkl.Input(shape=(cond_shape,), dtype=tf.float32)\n",
    "    log_prob_ = distribution.log_prob(x_, bijector_kwargs={'conditional_input': c_})\n",
    "    model = tfk.Model([x_,c_], log_prob_)\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=4e-5),loss=lambda _, log_prob: -log_prob)\n",
    "    return model, distribution\n",
    "\n",
    "def NPU(ymes,tsim,Rin,N,key):\n",
    "    # Inputs: \n",
    "    # ymes: Measured data provided in a histogram with N bins (N,)\n",
    "    # tsim: Simulated truth used to make the response\n",
    "    # Rin: Detector resolution matrix. First coordinate is the measured value and second coordinate is the truth level. (M,M)\n",
    "    # N: Total number of observations\n",
    "    # Returns samples from p(true|measured).  Would normally want the mode over true, which is equivalent to the MLE given p(true) is uniform.\n",
    "\n",
    "    M = 1500000 # number of sim used for the response\n",
    "    ts = []\n",
    "    lower = [max(0., tsim[i]-5*tsim[i]**0.5) for i in range(len(tsim))] # need positive values for poisson later\n",
    "    upper = tsim + 5*tsim**0.5\n",
    "    for k in range(len(ymes)):\n",
    "        ts.append( np.random.uniform(lower[k], upper[k], M) ) # M values with len(ymes) bins\n",
    "    ts = np.array(ts).T\n",
    "    # print(ts)\n",
    "    # print(np.sum(ts,-1,keepdims=True)) # sum over all bins, keep dim M (total sim data count)\n",
    "    \n",
    "    # ts = np.random.uniform(0,1,(M,len(ymes))) #M values with B bins\n",
    "    ts=N * ts/np.sum(ts,-1,keepdims=True) # N is total measured data count\n",
    "    # print(ts)\n",
    "    print(np.sum(ts,-1))\n",
    "\n",
    "    #pass the uniform prior thru the input response\n",
    "    ms = []\n",
    "    for j in range(len(ts)):\n",
    "        if j % 100000 == 0: \n",
    "            print(f\"{j}/{len(ts)}\") # len(ts) is M\n",
    "            # print(\"len(ts[j]):\", len(ts[j])) # len(ts[j]) is number of bins\n",
    "        # for i in range(len(ts[j])):\n",
    "        #     print(\"ts[j][i]:\", ts[j][i]) # len(ts[j]) is number of bins\n",
    "        m_hold = [np.random.poisson(ts[j][i]) for i in range(len(ts[j]))] #stat fluctuations\n",
    "        m_holds = np.random.multinomial(m_hold[0],Rin[:,0])\n",
    "        for i in range(1, len(ts[j])):\n",
    "            m_holds += np.random.multinomial(m_hold[i],Rin[:,i])\n",
    "        ms += [m_holds]\n",
    "        pass\n",
    "    ts = np.array(ts)\n",
    "    ms = np.array(ms)\n",
    "\n",
    "    n = len(ts)\n",
    "    x = ms #conditional feature\n",
    "    y = ts #learn p(y|x)\n",
    "    nx = N\n",
    "    ny = N\n",
    "\n",
    "    #Normalize the total number of events to make the NF easier to train\n",
    "    x = x/float(nx)\n",
    "    y = y/float(ny)\n",
    "\n",
    "    model,dist = MADE(y.shape[1],x.shape[1])\n",
    "    # Fit.\n",
    "    batch_size = 16384\n",
    "    myhistory = model.fit([y,x],\n",
    "                          y=np.zeros((len(x),0), dtype=np.float32), #dummy labels\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=1200,\n",
    "                          verbose = 1)\n",
    "\n",
    "    plt.plot(myhistory.history['loss'][10:-1])\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.savefig(\"npu_loss_{}\".format(key)+\".pdf\")\n",
    "    plt.clf()\n",
    "\n",
    "    # mle = MLE(dist,ymes/float(nx),y.shape[-1])\n",
    "    # print(mle)\n",
    "    nsample = 100000\n",
    "    mle = MLE(dist,ymes/float(nx),y.shape[-1]).numpy()\n",
    "    output = dist.sample(nsample, bijector_kwargs={'conditional_input': np.tile(ymes/float(nx),nsample).reshape([nsample,len(ymes)])}).numpy()\n",
    "    return output*ny, mle*ny, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1efe4c5-5274-41a9-9a6a-6ad74a8e965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior: (50000, 3)\n",
      "(50000, 3)\n",
      "posterior: (50000, 5)\n",
      "(50000, 5)\n",
      "posterior: (50000, 6)\n",
      "(50000, 6)\n",
      "posterior: (50000, 3)\n",
      "(50000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import corner\n",
    "\n",
    "for key, binvals, label in zip(T_sim_obs.keys(), R_BinVals, labels):\n",
    "    if key == 'mass' or key == 'sdms': continue\n",
    "    zjets = np.load(\"zjets_{}.npz\".format(key))\n",
    "    bins = np.array(zjets[\"bins\"])\n",
    "    nbins = len(bins)-1\n",
    "    p = np.array([1./nbins for i in range(1, nbins+1)])\n",
    "    bincents = 0.5*(bins[1:]+bins[:-1])\n",
    "    binsh = 0.07*(bins[1:]-bins[:-1])\n",
    "    \n",
    "    H_pT = zjets[\"H_pT\"]\n",
    "    H_pT_data = zjets[\"H_pT_data\"]\n",
    "    H_norm_pT = H_pT / H_pT.sum(axis=1, keepdims=True)\n",
    "    H_norm_pT_data = H_pT_data / H_pT_data.sum(axis=1, keepdims=True)\n",
    "\n",
    "    T_mc = np.sum(H_pT,axis=1)\n",
    "    D_mc = np.sum(H_pT,axis=0)\n",
    "    T_data = np.sum(H_pT_data,axis=1)\n",
    "    D_data = np.sum(H_pT_data,axis=0)\n",
    "    N_t = np.sum(T_data)\n",
    "    t = T_data\n",
    "\n",
    "    fbu=np.load(\"fpu_data_{}\".format(key)+\".npz\")\n",
    "    posterior = fbu['fbu'] \n",
    "    print(\"posterior:\", posterior.shape)\n",
    "    fbu_mean = np.mean(posterior,axis=0)\n",
    "    fbu_std = np.std(posterior,axis=0)\n",
    "    print(posterior.shape)\n",
    "    ibu = IBU(D_data, T_mc, H_norm_pT.T, 1, 1, 15)[15] \n",
    "    \n",
    "    N = D_data.sum()\n",
    "    # npu = NPU(D_data, T_mc, H_norm_pT.T, N, key)\n",
    "    # np.savez_compressed(\"npu_sim_{}\".format(key)+\".npz\", **{\"bins\": bincents, \"m\": D_data, \"t\": T_data, \"ibu\": ibu,  \n",
    "    #                                                     \"npu\": npu[0], \"mle\": npu[1] })\n",
    "    \n",
    "    npu_saved=np.load(\"npu_data_{}\".format(key)+\".npz\")\n",
    "    mean = npu_saved['npu'].mean(axis=0)\n",
    "    std = npu_saved['npu'].std(axis=0)\n",
    "    mle = npu_saved['mle'] \n",
    "\n",
    "    fig,gs = SetGrid(ratio=True) \n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    plt.xticks(fontsize=0)\n",
    "    ax1 = plt.subplot(gs[1],sharex=ax0)\n",
    "    \n",
    "    ax0.fill_between(bins, np.insert(t, len(t), np.array(t[-1])), step='post', alpha=0.3, color='tab:blue', label='Truth')\n",
    "    ax0.errorbar(x=bincents-binsh, y=ibu, label='IBU', color='tab:red',\n",
    "                 marker='o', linestyle='None', ms = 10, elinewidth=3, capsize=3)\n",
    "    ax0.errorbar(x=bincents+binsh,y=fbu_mean, yerr=fbu_std, label='FBU', color='tab:green', \n",
    "                 marker='v', linestyle='None', ms = 10, elinewidth=3, capsize=3)  \n",
    "    # ax0.errorbar(x=bincents, y=npu[1], yerr=npu[0].std(axis=0), label='NPU', color='tab:orange', \n",
    "    #              marker='^', linestyle='None', ms = 10, elinewidth=3, capsize=3)\n",
    "    ax0.errorbar(x=bincents, y=mle,   yerr=std, label='NPU mle', color='tab:orange', \n",
    "                 marker='^', linestyle='None', ms = 10, elinewidth=3, capsize=3)\n",
    "    # ax0.errorbar(x=bincents, y=mean,   yerr=std, label='NPU mean', color='tab:purple', \n",
    "    #              marker='^', linestyle='None', ms = 10, elinewidth=3, capsize=3)\n",
    "    ax0.set_ylabel(\"Normalized Cross Section [GeV$^{-1}$]\", fontsize=16)\n",
    "    # ax0.set_title(label, fontsize=18)\n",
    "    ax0.legend(frameon=False, loc=\"upper right\", fontsize=18)\n",
    "    ax0.tick_params(axis='y', which='major', labelsize=16)\n",
    "    ax0.ticklabel_format(scilimits=(-3,3), useMathText = True)\n",
    "    ax0.set_ylim(0, 1.3 * np.max(t))\n",
    "\n",
    "    r_fbu = np.divide(np.mean(posterior,axis=0), T_data)\n",
    "    r_ibu = np.divide(ibu, T_data)\n",
    "    r_npu = np.divide(mle, T_data)\n",
    "    # r_npu = np.divide(npu[1], T_data)\n",
    "    # ax1.grid(True, linestyle='dashed', linewidth=1)\n",
    "    ax1.axhline(y=1.0, color='tab:blue', linestyle='-', linewidth=2, alpha=0.5)\n",
    "    ax1.set_ylabel(\"Ratio to Truth\", fontsize=16)\n",
    "    ax1.set_xlabel(label, fontsize=16)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax1.set_ylim(0.5, 1.5)\n",
    "    ax1.errorbar(x=bincents, y=r_ibu, color='tab:red',   marker='o', \n",
    "                 linewidth=3,linestyle=\"None\",label='IBU', ms = 10, elinewidth=3, capsize=3)\n",
    "    ax1.errorbar(x=bincents, y=r_fbu,  color='tab:green',  marker='v',\n",
    "                 linewidth=3,linestyle=\"None\", label='FBU', ms = 10, elinewidth=3, capsize=3)\n",
    "    ax1.errorbar(x=bincents,   y=r_npu, color='tab:orange', marker='^',\n",
    "                 linewidth=3,linestyle=\"None\", label='NPU mle', ms = 10, elinewidth=3, capsize=3)\n",
    "\n",
    "    fig.savefig(\"npu_data_{}\".format(key)+\".pdf\")\n",
    "    fig.show()\n",
    "    fig.clf()\n",
    "\n",
    "    # figure = corner.corner(\n",
    "    # npu_saved['npu'],\n",
    "    # truths=T_data,\n",
    "    # hist_kwargs={\"color\": 'tab:orange', \"alpha\": 0.3, \"fill\": True, },\n",
    "    # color=\"tab:orange\",\n",
    "    # smooth=True,\n",
    "    # plot_contours=True,\n",
    "    # plot_density=False,\n",
    "    # plot_datapoints=False,\n",
    "    # fill_contours=True,\n",
    "    # # show_titles=True,\n",
    "    # # title_kwargs={\"fontsize\": 12},\n",
    "    # quantiles=[0.16, 0.5, 0.84],\n",
    "    # max_n_ticks=0,\n",
    "    # top_ticks=False,\n",
    "    # )  \n",
    "    # corner.corner(\n",
    "    # posterior,#[:, 1:-1],\n",
    "    # fig=figure,\n",
    "    # smooth=True,\n",
    "    # plot_contours=True,\n",
    "    # plot_density=False,\n",
    "    # plot_datapoints=False,\n",
    "    # fill_contours=True,\n",
    "    # color=\"tab:green\",\n",
    "    # )\n",
    "    # corner.overplot_lines(figure, T_data, color=\"deepskyblue\", linestyle='dashed', linewidth=4)\n",
    "    # corner.overplot_points(figure, T_data[None], color=\"deepskyblue\", marker='o', markersize=14)\n",
    "    # figure.savefig('corner_both_{}'.format(key)+'.pdf')\n",
    "    # figure.show()\n",
    "    # figure.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9580060f-f4ff-4b09-8319-18e932e2a225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, binvals, label in zip(T_sim_obs.keys(), R_BinVals, labels):\n",
    "    if key == 'mass' or key == 'sdms': continue\n",
    "    zjets = np.load(\"zjets_{}.npz\".format(key))\n",
    "    bins = np.array(zjets[\"bins\"])\n",
    "    nbins = len(bins)-1\n",
    "    p = np.array([1./nbins for i in range(1, nbins+1)])\n",
    "    bincents = 0.5*(bins[1:]+bins[:-1])\n",
    "    binsh = 0.1*(bins[1:]-bins[:-1])\n",
    "    \n",
    "    H_pT = zjets[\"H_pT\"]\n",
    "    H_pT_data = zjets[\"H_pT_data\"]\n",
    "    H_norm_pT = H_pT / H_pT.sum(axis=1, keepdims=True)\n",
    "\n",
    "    T_mc = np.sum(H_pT,axis=1)\n",
    "    D_mc = np.sum(H_pT,axis=0)\n",
    "    T_data = np.sum(H_pT_data,axis=1)\n",
    "    D_data = np.sum(H_pT_data,axis=0)\n",
    "    N_t = np.sum(T_data)\n",
    "    t = T_data\n",
    "\n",
    "    fbu=np.load(\"fpu_data_{}\".format(key)+\".npz\")\n",
    "    posterior = fbu['fbu']\n",
    "    ibu = IBU(D_data, T_mc, H_norm_pT.T, 1, 1, 15)[15] \n",
    "    \n",
    "    N = D_data.sum()\n",
    "    # npu = NPU(D_data, T_mc, H_norm_pT.T, N, key)\n",
    "    # np.savez_compressed(\"npu_{}\".format(key)+\".npz\", **{\"bins\": bincents, \"m\": D_data, \"t\": T_data, \"ibu\": ibu,\n",
    "    #                                                     \"mean\": npu[0].mean(axis=0), \"std\": npu[0].std(axis=0), \"mle\": npu[1]})\n",
    "    \n",
    "    npu_saved=np.load(\"npu_data_{}\".format(key)+\".npz\")\n",
    "    mean = npu_saved['npu'].mean(axis=0)\n",
    "    std = npu_saved['npu'].std(axis=0)\n",
    "    mle = npu_saved['mle'] \n",
    "\n",
    "    fig,gs = SetGrid(ratio=True) \n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    plt.xticks(fontsize=0)\n",
    "    ax1 = plt.subplot(gs[1],sharex=ax0)\n",
    "\n",
    "    # Log-y plots\n",
    "    ax0.fill_between(bins, np.insert(t, len(t), np.array(t[-1])), step='post', alpha=0.3, color='tab:blue', label='Truth')\n",
    "    ax0.errorbar(x=bincents-binsh, y=ibu, label='IBU', color='tab:red',\n",
    "                 marker='o', linestyle='None', ms = 10, elinewidth=3, capsize=3)\n",
    "    ax0.errorbar(x=bincents, y=mle,   yerr=std, label='NPU', color='tab:orange', \n",
    "                 marker='^', linestyle='None', ms = 10, elinewidth=3, capsize=3)\n",
    "    # ax0.errorbar(x=bincents,       y=npu[1],      yerr=npu[0].std(axis=0), label='NPU', color='tab:orange', marker='X', linestyle='None')\n",
    "    ax0.errorbar(x=bincents+binsh,y=np.mean(posterior,axis=0), yerr=np.std(posterior,axis=0), label='FBU', color='tab:green', \n",
    "                 marker='v', linestyle='None', ms = 10, elinewidth=3, capsize=3)   \n",
    "    ax0.set_ylabel(\"Normalized Cross Section [GeV$^{-1}$]\", fontsize=16)\n",
    "    ax0.legend(frameon=False, loc=\"upper right\", fontsize=18)\n",
    "    ax0.tick_params(axis='y', which='major', labelsize=16)\n",
    "    ax0.set_yscale('log')\n",
    "    ax0.set_ylim(0.1*np.min(t), 10 * np.max(t))\n",
    "\n",
    "    r_fbu = np.divide(np.mean(posterior,axis=0), T_data)\n",
    "    r_ibu = np.divide(ibu, T_data)\n",
    "    r_npu = np.divide(mle, T_data)\n",
    "    ax1.axhline(y=1.0, color='tab:blue', linestyle='-', linewidth=2, alpha=0.5)\n",
    "    ax1.set_ylabel(\"Ratio to Truth\", fontsize=16)\n",
    "    ax1.set_xlabel(label, fontsize=16)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax1.set_ylim(0.5, 1.5)\n",
    "    # ax1.grid(True, linestyle='dashed', linewidth=1)\n",
    "    ax1.errorbar(x=bincents, y=r_ibu, color='tab:red',   marker='o', \n",
    "                 linewidth=3,linestyle=\"None\",label='IBU', ms = 10, elinewidth=3, capsize=3)\n",
    "    ax1.errorbar(x=bincents, y=r_fbu,  color='tab:green',  marker='v',\n",
    "                 linewidth=3,linestyle=\"None\", label='FBU', ms = 10, elinewidth=3, capsize=3)\n",
    "    ax1.errorbar(x=bincents,   y=r_npu, color='tab:orange', marker='^',\n",
    "                 linewidth=3,linestyle=\"None\", label='NPU', ms = 10, elinewidth=3, capsize=3)\n",
    "    fig.savefig(\"npu_{}_logy\".format(key)+\".pdf\")\n",
    "    fig.show()\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d306887-b527-439d-adb2-f8693d916b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
